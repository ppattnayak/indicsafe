# IndicSafe

*A Benchmark for Evaluating Multilingual LLM Safety in South Asia*  
*(ARR 2025)*

---

## 📘 Overview

**IndicSafe** is a multilingual safety and alignment benchmark designed to evaluate large language models across major **Indic languages**.  
It includes diverse prompts covering safety-critical categories such as:
- Hate speech  
- Harassment  
- Misinformation  
- Self-harm and violence  
- Sensitive or unethical content  

This benchmark aims to provide a standardized evaluation suite for safety alignment research in multilingual and low-resource settings.

---

## 🧩 Repository Status

This is a **teaser repository** for the upcoming **IndicSafe Benchmark**.  
The dataset and evaluation tools will be released soon.

### Coming Soon
- 🔹 Full multilingual dataset (~6K prompts)  
- 🔹 Evaluation scripts and benchmark metrics  
- 🔹 Model comparison baselines  
- 🔹 Documentation and reproducibility guide  

---

## 📄 License

Currently, this repository (README and metadata) is licensed under the [MIT License](LICENSE).  
Upon release:
- **Code and tools** → MIT License  
- **Dataset** → Creative Commons Attribution-NonCommercial 4.0 International (CC BY-NC 4.0)

---

## 📝 Citation

If you’d like to reference or discuss this work, please cite the following paper:

> **IndicSafe: Multilingual Safety Benchmark for Indic Languages**  
> (Arxiv Link) 
> ARR 2025 (Meta Score 4) — Planned commitment to ACL 2026

BibTeX:
```bibtex
@article{indicsafe2025,
  title={IndicSafe: Multilingual Safety Benchmark for Indic Languages},
  author={Pattnayak, P. and others},
  year={2025},
  journal={ARR},
  note={Planned commitment to ACL 2026}
}
